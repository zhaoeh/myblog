---
layout:     post
title:      Kafka
subtitle:   Kafka入门
categories: [MQ系列]
mermaid: false
sequence: false
flow: false
mathjax: false
mindmap: false
mindmap2: false
---

# 1. Kafka的模式
和其他MQ原理类似，Kafka也是作为一个消息中间件独立存在，目前比较流行。   
Apache Kafka 使用了一种独特的消息传递模式，它既不是传统意义上的**纯 Push 模式**，也不是完全的**纯 Pull 模式**。Kafka 的消费者实际上是基于**Pull 模式**来获取消息，但其设计特性让它表现出一些类似于 Push 模式的行为。

### **Kafka 的消息消费模型**

#### **Pull 模式**
- 消费者通过向 Kafka **主动拉取（Pull）**消息的方式来消费数据。
- 消费者决定何时请求数据以及请求多少数据。
- Kafka 不会主动将数据推送给消费者。

#### **Push 模式**
- 传统的 Push 模式是由消息代理（如 RabbitMQ）主动将消息推送给消费者。
- 代理决定了消息的推送速率和频率，消费者被动接收。

---

### **Kafka 的 Pull 模式与 Push 模式的比较**

| 特性                  | Kafka Pull 模式                                     | Push 模式                           |
|-----------------------|----------------------------------------------------|-------------------------------------|
| **消息拉取方式**     | 消费者决定何时拉取消息及拉取的速率。                  | 消息代理主动推送消息给消费者。        |
| **流量控制**         | 消费者可根据自身的处理能力控制消费速度。              | 如果推送过快，消费者可能会被淹没。   |
| **数据处理延迟**     | 消费者可以选择何时开始消费，适合高吞吐量场景。        | 推送速度完全由代理控制，消费者被动接受。 |
| **灵活性**           | 消费者可以选择从特定的偏移量开始消费（重放数据）。    | 重新消费历史数据可能会很复杂或受限。  |

---

### **为什么 Kafka 使用 Pull 模式？**

Kafka 选择 Pull 模式的原因主要包括以下几点：

1. **高吞吐量需求**
   - 在高吞吐量的场景下，Pull 模式允许消费者根据自己的处理能力控制消费速率，避免系统过载。
   - 如果使用 Push 模式，消费者可能无法快速处理代理推送过来的大量数据。

2. **灵活的消费**
   - Kafka 允许消费者指定从某个偏移量（Offset）开始消费，这种灵活性非常适合需要重新处理历史数据的场景（例如，错误修复、审计）。

3. **简化代理的复杂性**
   - 在 Pull 模式下，Kafka 不需要跟踪每个消费者的处理能力，从而简化了 Broker 的设计，提升了 Kafka 的扩展性。

4. **消息批量拉取**
   - 消费者可以按需从 Broker 拉取一批消息，这种批量操作降低了网络通信的开销，提高了效率。

5. **实时性需求**
   - 虽然 Kafka 是 Pull 模式，但由于消费者可以持续地拉取消息（长轮询），在实际使用中也可以接近实时性，满足实时数据处理的需求。

---

### **Kafka 与 Push 模式的关系**

虽然 Kafka 的消费是 Pull 模式，但在数据生产（Producer）阶段可以看作是**Push 模式**：

- 生产者会主动将数据推送到 Kafka 的分区（Partition）。
- Broker 对数据进行持久化存储，消费者随后拉取消息。

这种分离生产与消费的机制让 Kafka 既可以支持实时消息流处理，也能用于离线数据处理。

---

### **总结**

- Kafka 的消费者是基于 **Pull 模式** 设计的，但由于可以实现持续拉取，表现上也能接近实时性。
- Pull 模式赋予消费者更多的控制权，特别是在高吞吐量和灵活数据消费场景中表现优越。
- Kafka 并没有完全采用 Push 模式，因为那样可能会导致消费者过载、丢失灵活性，降低系统的可靠性和可扩展性。

所以，Kafka 是 Pull 模式，并通过优化长轮询机制和批量消费等特性，表现出比传统 Pull 模式更高效的特性。

# 2. Kafka消费者如何通过pull模式立即消费队列中的消息？
Kafka 通过一系列机制来确保分区中的数据能**尽快**被消费组消费，尽管它本质上采用的是**Pull 模式**。以下是 Kafka 确保分区中有数据时消费组能立即消费的关键设计和优化机制：

---

### **1. 长轮询机制（Long Polling）**

Kafka 消费者通过调用 `poll()` 方法从分区中拉取数据。如果分区暂时没有可用数据，消费者不会立即返回，而是可以设置一个超时时间进行等待（长轮询）。这种机制避免了消费者频繁发送请求，同时可以在新数据到达时立即消费。

#### **相关配置参数：**
- **`fetch.min.bytes`**  
  - 指定消费者每次拉取的最小数据量。如果数据不足，消费者会等待更多数据到达。
  - 目的：减少网络请求次数，提高吞吐量。

- **`fetch.max.wait.ms`**  
  - 指定消费者在没有达到 `fetch.min.bytes` 时最多等待的时间。
  - 目的：在延迟和吞吐量之间取得平衡。

- **`max.poll.interval.ms`**  
  - 消费者每次调用 `poll()` 的最大允许间隔时间，防止消费者过于空闲。

> **工作方式**：如果分区中有新数据产生，Kafka Broker 会立即响应消费者的拉取请求；否则消费者会等待直至超时或数据可用。

---

### **2. 消费组协调（Group Coordination）**

Kafka 使用消费组（Consumer Group）来管理消费行为：
- **分区分配（Partition Assignment）：** 消费组中的消费者分配到特定分区，确保每个分区被一个消费者独占消费。
- **自动负载均衡：** 当新的消费者加入或现有消费者退出时，Kafka 会重新分配分区。

这种机制确保了每个分区的数据都能被一个活跃的消费者处理。

---

### **3. 高效的网络 I/O 模型**

Kafka 的 Broker 和消费者使用高效的网络 I/O 模型来快速传递消息：
- **零拷贝（Zero-Copy）：** Kafka Broker 使用零拷贝技术将消息从磁盘直接传输到消费者，减少了数据在内存中的复制次数。
- **批量传输：** 消费者一次可以拉取多条消息，大大提高了吞吐量和响应速度。

---

### **4. 消息批次处理**

Kafka 允许消费者按批次消费数据，而不是逐条消费：
- 消费者每次从 Broker 拉取一批消息并缓存在本地内存中。
- 批量拉取和处理降低了延迟，提高了数据传输和处理效率。

---

### **5. Consumer Rebalance Listener**

Kafka 提供 `ConsumerRebalanceListener`，当分区分配发生变化时（如新消费者加入或退出消费组），可以执行特定的逻辑。例如：
- 在消费者重平衡前后提交偏移量（Offsets）。
- 在新分区分配后立即触发消费行为。

---

### **6. 高效的日志存储和索引机制**

Kafka 的分区数据存储在日志文件中，并使用段文件（Segment）和索引加速消息的定位和读取：
- 消息以追加日志的形式存储，写入效率极高。
- 消费者通过偏移量（Offset）精确定位所需消息，从而减少读取延迟。

当有新消息写入分区时，消费者可以快速获取新数据。

---

### **7. 心跳机制（Heartbeat）**

Kafka 消费者通过发送心跳（Heartbeat）告知 Kafka 自己的状态：
- Broker 知道消费者是否活跃，并确保新数据始终由活跃消费者处理。
- 如果消费者长时间未发送心跳，Kafka 会触发分区重新分配，保证新分区被及时消费。

#### **相关参数：**
- **`heartbeat.interval.ms`**  
  消费者向 Broker 发送心跳的频率。

- **`session.timeout.ms`**  
  Broker 判断消费者失联的超时时间。

---

### **8. 异步 Producer 提高数据可用性**

Kafka 的生产者可以异步发送数据到分区，减少生产延迟并提高吞吐量：
- 数据几乎实时写入分区，分区变得“有数据可消费”。
- 消费者长轮询会在新数据写入时立即返回。

#### **生产者相关参数：**
- **`acks`**  
  控制数据写入的确认策略（例如写入 Leader 或所有副本）。

- **`linger.ms`**  
  延迟发送的时间窗口，可以通过批量发送提高效率。

---

### **9. 内部队列和线程模型**

消费者通常使用多线程模型：
- 拉取到的数据放入内部队列（例如 `BlockingQueue`）。
- 消费者线程从队列中消费数据，保证了高效的处理和即时性。

---

### **Kafka 近实时消费的效果来源**

Kafka 的 Pull 模式虽然需要消费者主动拉取数据，但通过以下特性接近 Push 模式的实时性：
1. **长轮询和 Broker 即时响应：** 保证消费者能尽快拉取新数据。
2. **批量拉取和批量传输：** 提高了数据消费效率。
3. **生产者实时写入：** 数据几乎瞬间可被消费。
4. **分区独占消费：** 避免了消费组内竞争，提高了处理速度。

---

### **总结**

Kafka 确保分区中有数据时能立即被消费组消费，主要依赖以下机制：
- **长轮询机制，减少空轮询开销**。
- **高效分区分配与负载均衡**，保证分区被活跃消费者消费。
- **高效的存储与传输模型**，提升消费速度。

通过这些设计，Kafka 在 Pull 模式下能实现接近 Push 模式的实时消费体验，同时保持了更高的灵活性和可靠性。

# 3. kafka的分组消费，以及是否会删除Broker中的消息？
### **Kafka 消费者分组（Consumer Group）是什么？**

Kafka 的**消费者分组**（Consumer Group）是 Kafka 消费者管理机制的核心概念，用于实现消息的并行处理和横向扩展。

- **定义：** 一个消费者分组由多个消费者实例组成，共同消费一个或多个主题（Topic）中的消息。
- **特性：**
  1. **分区分配：** 
     - 每个分区只能被同一个消费组内的一个消费者消费。
     - 如果消费组内的消费者数量多于分区数量，部分消费者会闲置。
     - 如果消费者数量少于分区数量，部分消费者会消费多个分区。
  2. **独立消费：**
     - 不同消费组之间相互独立，互不影响。
     - 每个消费组都会维护自己的偏移量（Offset），即每个消费组对消息的消费记录是独立的。

> **举例：**  
如果一个主题有 4 个分区，且有 2 个消费组（组 A 和组 B）：  
- 消费组 A 的两个消费者会消费所有分区（每个消费者消费 2 个分区）。
- 消费组 B 的消费者同样可以消费所有分区，不受组 A 的影响。

---

### **消息消费后是否删除队列中的消息？**

**Kafka 的消息不会在消费后立即删除，和传统的消息队列（如 RabbitMQ）有所不同。**

1. **消息存储在分区中：**
   - Kafka 的消息存储在主题的分区（Partition）中，以追加日志的形式写入。
   - 消息不会因为被消费而删除，消费组的消费者会根据自己的偏移量（Offset）读取消息。

2. **消息删除机制：**
   - Kafka 的消息保留策略与消费状态无关，而是由主题的配置决定：
     - **基于时间：** 例如消息保留 7 天，`log.retention.hours=168`。
     - **基于大小：** 当分区的日志文件达到一定大小时，旧数据会被清理，`log.retention.bytes`。

因此，Kafka 不会像传统队列那样消费后立即删除消息，而是允许消费者独立按偏移量消费数据，同时支持历史数据的重放。

---

### **Kafka 的消息存储在哪里？是队列还是其他地方？**

Kafka 的消息存储在磁盘上，并按照主题（Topic）和分区（Partition）组织，而不是传统意义上的**队列**。

1. **存储结构：**
   - 每个主题被划分为多个分区，每个分区是一个有序的、持久化的日志文件。
   - 消息会被追加到分区的末尾。
   - 每条消息都有一个唯一的偏移量（Offset）用于标识。

2. **区别于队列：**
   - **传统队列：** FIFO（先进先出），消费后立即删除。
   - **Kafka：** 基于日志存储，消息可重复消费，不受消费状态影响。

3. **分区的作用：**
   - 分区是 Kafka 并行处理和高吞吐量的基础。
   - 每个分区可以独立地存储、写入和读取数据。

---

### **Kafka 支持异步消费还是同步消费？**

Kafka 消费支持同步和异步两种消费模式，具体由消费者的实现方式决定：

1. **同步消费：**
   - 消费者会拉取消息后，逐条或逐批处理。
   - 在完成处理并提交偏移量后，再继续拉取下一批消息。

2. **异步消费：**
   - 消费者在拉取消息后，将消息放入本地队列或线程池，异步处理。
   - 可以通过手动管理偏移量提交来控制消费的可靠性。

> **开发者可以根据需求选择同步或异步模式：**
- 同步消费更简单，适合处理逻辑较轻且对数据处理顺序要求严格的场景。
- 异步消费可以提高并发能力，适合高吞吐量场景。

---

### **消费者消费消息后是手动确认还是自动确认？**

Kafka 提供了**自动提交**和**手动提交**两种偏移量提交方式。

1. **自动提交（Auto Commit）：**
   - 消费者可以通过配置 `enable.auto.commit=true` 开启自动提交。
   - 默认每隔 5 秒（`auto.commit.interval.ms`）提交一次偏移量。
   - **优点：** 简化操作，不需要显式提交偏移量。
   - **缺点：** 可能导致未处理完的消息被认为已消费，存在数据丢失风险。

2. **手动提交（Manual Commit）：**
   - 开发者需要在代码中显式调用 `commitSync()` 或 `commitAsync()` 提交偏移量。
   - **`commitSync()`**：同步提交，确保偏移量已成功提交。
   - **`commitAsync()`**：异步提交，性能更高，但可能存在失败的风险。
   - **优点：** 提高数据处理的可靠性，确保消息只有在成功处理后才被标记为已消费。
   - **缺点：** 增加代码复杂性。

> **实际场景中推荐手动提交：**
- 如果数据处理失败（如抛出异常），可以避免偏移量被错误提交，从而支持数据重试。

---

### **总结**

1. **消费者分组：** Kafka 的消费者分组是 Kafka 并行消费模型的核心，一个消费组中的消费者共同消费分区消息。
2. **消息消费后不会立即删除：** Kafka 的消息存储在分区中，不因消费而删除，清理机制由时间或存储空间限制决定。
3. **存储方式：** Kafka 使用分区日志文件存储消息，而不是传统队列。
4. **同步与异步消费：** Kafka 支持同步和异步消费，开发者可以根据需求选择合适的实现方式。
5. **手动与自动确认：**
   - 自动确认（简单但有丢失数据风险）。
   - 手动确认（可靠但需要更多开发控制）。

这些特性让 Kafka 适用于高吞吐量、分布式并行处理的场景，同时具备灵活的消费模型和持久化机制。

# 4. Kafka防止重复消费、消息丢失和顺序消费的机制
Kafka 在设计上通过一系列机制来防止消息重复消费、确保消息不丢失，以及保持消息的顺序性（先进先出，FIFO）。以下详细回答你的问题。

---

### **1. Kafka 如何防止消息重复消费？**

Kafka 的防止重复消费机制取决于消费者的偏移量（Offset）管理：

#### **消费者偏移量管理**
- Kafka 使用 **偏移量（Offset）** 追踪每个消费者在分区中消费到的位置。
- 如果消费者重复消费消息，大多数情况下是因为偏移量管理不当。

#### **具体防止重复消费的机制**
1. **手动提交偏移量：**
   - 消费者处理消息后手动提交偏移量。
   - 偏移量在消息处理完成后才更新，防止处理失败的消息被标记为已消费。

2. **幂等性设计：**
   - 消费端可以通过业务逻辑保证幂等性，即同一条消息被重复处理多次，结果仍然一致。
   - 比如：
     - 用唯一消息 ID 做去重。
     - 对数据库操作设置唯一约束。

3. **消费者组（Consumer Group）：**
   - Kafka 确保同一个分区的数据在一个消费组内只会被一个消费者实例消费，避免同一分区的数据被重复消费。

4. **事务性生产者和消费者：**
   - Kafka 支持事务，将生产和消费操作组合为原子性操作。
   - 如果启用事务，消费后的消息偏移量提交与下游处理操作同时完成，避免重复消费。

#### **避免重复消费的核心策略**
- 正确管理偏移量。
- 配合业务逻辑实现幂等性。
- 在需要绝对一致性场景下使用 Kafka 的事务机制。

---

### **2. Kafka 如何确保消息不丢失？**

Kafka 提供多个机制来保障消息的可靠性，确保消息在生产、存储、消费的过程中不会丢失。

#### **2.1 消息生产端的保障**
1. **确认机制（Acknowledgments）：**
   - Kafka 生产者支持配置 `acks` 参数：
     - `acks=0`：生产者不会等待任何确认，有丢失风险。
     - `acks=1`：生产者等待分区主节点的确认。
     - `acks=all`（推荐）：生产者等待所有副本（包括主副本和从副本）的确认，确保消息已持久化到多个副本。

2. **重试机制：**
   - Kafka 生产者支持配置重试次数（`retries`）和重试间隔（`retry.backoff.ms`）。
   - 网络抖动或暂时性失败时，生产者会自动重试。

3. **幂等性生产者（Idempotent Producer）：**
   - 启用幂等性（`enable.idempotence=true`）后，Kafka 生产者可以确保即使发生重试，消息也不会被重复写入。

#### **2.2 消息存储端的保障**
1. **复制机制：**
   - Kafka 使用副本机制（Replication）确保数据可靠。
   - 每个分区的数据会被复制到多个副本（默认 3 个），即使主副本故障，也能从 ISR（同步副本集）中选出新主副本继续提供服务。

2. **持久化机制：**
   - 消息写入磁盘，Kafka 使用文件系统缓存，数据持久化到磁盘后再确认。

3. **ISR 副本管理：**
   - Kafka 的 ISR 副本集只包含与主分区保持同步的副本，只有这些副本才有资格成为新的主分区。

#### **2.3 消息消费端的保障**
1. **手动提交偏移量：**
   - 消费者处理完消息后手动提交偏移量，确保消息处理完成才更新消费进度。

2. **消费重试机制：**
   - 消费端可以实现重试逻辑，对于处理失败的消息可以重新消费。

3. **事务性消费：**
   - 消费者可以启用事务，将消费和偏移量提交作为原子操作，确保消息不会丢失。

---

### **3. Kafka 如何确保消息的顺序性（FIFO 特性）？**

Kafka 的顺序性由分区和分区内的消息顺序保证。

#### **3.1 分区内的顺序性**
1. **分区是有序的日志：**
   - 每个分区内的消息以追加日志的形式存储，天然保持消息的写入顺序。
   - 消费者会按偏移量顺序读取消息，确保消费的顺序性。

2. **单消费者消费一个分区：**
   - 同一分区的数据只会被一个消费者消费，因此消费顺序与生产顺序一致。

#### **3.2 分区间的顺序性**
- Kafka 不保证跨分区的全局顺序。
- 如果需要全局顺序性：
  1. **单分区：**
     - 将所有消息写入同一个分区。
     - 缺点：吞吐量受限，不能利用分区的并行性。
  2. **消息分组：**
     - 使用某些字段（如订单 ID）作为分区键，确保相同分区键的消息总是写入同一个分区。

#### **3.3 幂等性和事务的配合**
- Kafka 支持幂等性生产者，确保消息即使重复发送，顺序也不会错乱。
- 事务可以保证多个消息的写入和消费操作的顺序一致。

---

### **总结：Kafka 如何解决你的问题？**

| 问题                             | Kafka 的解决机制                                                                                  |
|----------------------------------|--------------------------------------------------------------------------------------------------|
| **如何防止消息重复消费？**       | 管理偏移量（手动提交偏移量）、幂等性设计、事务性消费、消费者分组确保分区独占消费。                 |
| **如何确保消息不丢失？**         | 通过副本机制、幂等性生产者、事务机制，以及消费端手动提交偏移量，确保生产、存储和消费的可靠性。     |
| **如何保持消息的顺序性？**       | 分区内的顺序由偏移量管理保证；需要全局顺序性时，可以通过单分区或分区键将相关消息发送到同一分区。    |

Kafka 的核心机制（偏移量管理、分区和副本）使其成为高吞吐量、强一致性和灵活性的分布式消息系统。

# 5. Kafka在编码中的newTopic
在使用 Apache Kafka 时，`NewTopic` 是 Kafka AdminClient 提供的一个类，用于创建新的主题（topic）。下面对 `NewTopic` 进行详细解释，包括其构造方法和参数含义，以及分区（Partition）和副本（Replica，常指 Pod）的意义。

---

## **`NewTopic` 的构造方法**

`NewTopic` 是 Kafka 客户端的一部分，通常用来在 Kafka 集群中创建一个新主题。它的常见构造方法如下：

```java
public NewTopic(String name, int numPartitions, short replicationFactor)
```

### **参数含义**

1. **`name`**（`String` 类型）  
   - 表示主题名称（Topic Name）。
   - 在 Kafka 集群中，主题是逻辑上的一个数据流集合。

2. **`numPartitions`**（`int` 类型）  
   - 指定该主题的分区数量。
   - 每个分区（Partition）是一个独立的日志文件，Kafka 会在其中存储该分区对应的数据。
   - 数据会按照 Key 的哈希值被分配到不同的分区，或随机分配。

3. **`replicationFactor`**（`short` 类型）  
   - 指定每个分区的副本数量（Replica）。
   - 副本是分区的完整拷贝，分布在不同的 Kafka Broker 上，用于提高可用性和容错能力。
   - 副本中只有一个被选为 Leader，其余为 Follower，所有的读写操作都通过 Leader 进行。

---

### **分区（Partition）的含义**

1. **概念**  
   分区是 Kafka 中存储数据的最小单位。一个主题可以包含多个分区。每个分区以顺序追加的日志形式存储消息。

2. **作用**  
   - **扩展性（Scalability）：** 分区允许主题中的消息分布在多个 Broker 中，从而提高吞吐量。  
   - **并行处理：** 消费者可以并行地读取多个分区中的数据，提升处理效率。

3. **数据分配**  
   数据在分区中的分配由 **分区键（Key）** 决定。如果 Key 存在，则会基于 Key 的哈希值分配到对应的分区；如果没有 Key，则 Kafka 会随机分配分区。

---

### **副本（Replica，Pod）的含义**

1. **概念**  
   每个分区可以有多个副本，这些副本分布在不同的 Broker 上，用于提供高可用性和容错能力。

2. **作用**  
   - **高可用性（High Availability）：** 如果一个 Broker 或 Leader 副本失败，Kafka 会自动选举新的 Leader 副本。  
   - **容错（Fault Tolerance）：** 即使部分 Broker 出现故障，其他副本仍然可以继续提供服务。

3. **角色**  
   - **Leader 副本：** 负责处理所有的读写请求。  
   - **Follower 副本：** 跟随 Leader，复制其数据，在 Leader 故障时被选为新的 Leader。

4. **副本与分区的关系**  
   - 每个分区都有一个 Leader 和多个 Follower。  
   - 副本数量（`replicationFactor`）通常设置为 3，表示每个分区有 1 个 Leader 和 2 个 Follower。

---

### **示例代码**

以下代码展示了如何使用 `NewTopic` 创建一个主题：

```java
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.AdminClientConfig;
import org.apache.kafka.clients.admin.NewTopic;

import java.util.Collections;
import java.util.Properties;

public class KafkaTopicCreation {
    public static void main(String[] args) {
        // 配置 Kafka AdminClient
        Properties props = new Properties();
        props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        try (AdminClient adminClient = AdminClient.create(props)) {
            // 创建一个名为 "my-topic" 的主题，5 个分区，3 个副本
            NewTopic newTopic = new NewTopic("my-topic", 5, (short) 3);
            adminClient.createTopics(Collections.singletonList(newTopic)).all().get();
            System.out.println("Topic created successfully!");
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

---

### **总结**

- **分区（Partition）：** 数据分布和并行处理的基本单位。  
- **副本（Replica）：** 提高高可用性和容错能力。  
- **`NewTopic` 参数：**  
  - `name`：主题名称。  
  - `numPartitions`：分区数量，决定并行度和吞吐量。  
  - `replicationFactor`：副本数量，决定可靠性和容错能力。

理解分区和副本的工作原理，有助于更好地设计 Kafka 的主题和分布式系统架构。    